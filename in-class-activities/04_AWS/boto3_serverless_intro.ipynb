{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f00d587",
   "metadata": {},
   "source": [
    "## Introduction to Boto3 and AWS Serverless Solutions\n",
    "\n",
    "Let's say that we wanted to detect objects in an image, extract text from images, or perform sentiment analysis on a text. We could write and train our own classifiers, run our classifier on a server (e.g. an EC2 instance) and use this to make predictions. This requires a lot of time and energy in selecting the appropriate hardware, software, techniques, etc. necessary to perform these operations.\n",
    "\n",
    "For this reason, all the major cloud providers offer serverless \"functions as a service\" which are pre-trained/coded models that you simply need to provide data to and you will receive a response. Your cloud provider (e.g. AWS) will spin up the compute instances necessary to actually run the code. \n",
    "\n",
    "You can access all of these through the AWS Console, but it is easier to integrate them into your existing code via the Boto3 SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba93331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168eac2",
   "metadata": {},
   "source": [
    "For instance, we can interact with AWS' image recognition functions like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58af98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rekog = boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7840ef38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Person', 99.89472198486328),\n",
       " ('Human', 99.89472198486328),\n",
       " ('Outdoors', 94.6645278930664),\n",
       " ('Road', 94.50630187988281),\n",
       " ('Path', 94.26421356201172)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detect the objects in the provided image\n",
    "with open('uchicago.jpg', 'rb') as image:\n",
    "    response = rekog.detect_labels(Image={'Bytes': image.read()})\n",
    "    \n",
    "[(label['Name'], label['Confidence']) for label in response['Labels']][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c9abac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also count number of instances of each label: e.g. \"Person\" - label 0\n",
    "len(response['Labels'][0]['Instances']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae40030",
   "metadata": {},
   "source": [
    "We can use rekognition to detect text in images as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42b3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('uchicago_sign.jpg', 'rb') as image:\n",
    "    response = rekog.detect_text(Image={'Bytes': image.read()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c44468f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected text:Vita\n",
      "Confidence: 81.73%\n",
      "Detected text:FCA\n",
      "Confidence: 37.99%\n",
      "Detected text:COLO\n",
      "Confidence: 13.49%\n",
      "Detected text:caria\n",
      "Confidence: 31.49%\n",
      "Detected text:latur\n",
      "Confidence: 37.75%\n",
      "Detected text:THE UNIVERSITY OF\n",
      "Confidence: 99.62%\n",
      "Detected text:CHICAGO\n",
      "Confidence: 99.58%\n"
     ]
    }
   ],
   "source": [
    "for text in response['TextDetections']:\n",
    "    if text['Type'] == 'LINE':\n",
    "        print ('Detected text:' + text['DetectedText'])\n",
    "        print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a060762",
   "metadata": {},
   "source": [
    "If you have custom workflows, Rekognition might not be the best option, but for many general applications, this will likely handle everything that you need to do and is really easy to use.\n",
    "\n",
    "We can also perform common NLP tasks like detecting the sentiment of a text via AWS Comprehend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f426c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE {'Positive': 0.9994707703590393, 'Negative': 4.922328662360087e-05, 'Neutral': 0.00045435165520757437, 'Mixed': 2.5665714929345995e-05}\n"
     ]
    }
   ],
   "source": [
    "comprehend = boto3.client('comprehend')\n",
    "\n",
    "response = comprehend.detect_sentiment(Text='This class is fun!',\n",
    "                                       LanguageCode='en')\n",
    "\n",
    "print(response['Sentiment'], response['SentimentScore'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57fadc9",
   "metadata": {},
   "source": [
    "...and perform quick translations from one language (here, automatically detected) into another one (French) on command with AWS Translate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2b33e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bonjour, je m'appelle Jon\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate = boto3.client('translate')\n",
    "\n",
    "response = translate.translate_text(Text='Hello, my name is Jon',\n",
    "                                    SourceLanguageCode='auto',\n",
    "                                    TargetLanguageCode='fr')\n",
    "response['TranslatedText']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eab878d",
   "metadata": {},
   "source": [
    "You will have a chance to practice using more of these serverless tools in the DataCamp course that we've assigned as one of the readings for Monday's class, but this should give you a taste of some of the functionality that is available to you right out of the box.\n",
    "\n",
    "----\n",
    "\n",
    "**AWS Lambda Functions**\n",
    "\n",
    "We can also create our own custom serverless functions as well, though, via AWS Lambda... \n",
    "\n",
    "*Go to AWS Console and create/deploy sample Lambda function (called `hello_world`):*\n",
    "\n",
    "```python\n",
    "def lambda_handler(event, context):\n",
    "    # test: {'key1': 1, 'key2': 2}\n",
    "    total = event['key1'] + event['key2']\n",
    "    return total\n",
    "```\n",
    "\n",
    "Can write code of arbitrary complexity in here, assuming it's going to be a relatively quick operation (e.g. less than 300s)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c906cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aws_lambda = boto3.client('lambda')\n",
    "\n",
    "test_data = {'key1': 1, 'key2': 2}\n",
    "\n",
    "# run synchronously:\n",
    "r = aws_lambda.invoke(FunctionName='hello_world',\n",
    "                      InvocationType='RequestResponse',\n",
    "                      Payload=json.dumps(test_data))\n",
    "json.loads(r['Payload'].read()) # print out response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05afb8b",
   "metadata": {},
   "source": [
    "Currently still running all of this code serially, though. Real advantage of\n",
    "Lambda is that it scales automatically to meet concurrent demand, meaning\n",
    "that it will automatically parallelize based on how many concurrent invocations\n",
    "it receives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb04957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. write function to invoke our function for us and pass in data:\n",
    "def invoke_function(data):\n",
    "    r = aws_lambda.invoke(FunctionName='hello_world',\n",
    "                       InvocationType='RequestResponse',\n",
    "                       Payload=json.dumps(data))\n",
    "    return json.loads(r['Payload'].read())\n",
    "\n",
    "# 2. Demo that lambda function will scale out if called concurrently on different threads locally\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    results = executor.map(invoke_function, [test_data for _ in range(4)])\n",
    "\n",
    "# 3. In AWS Console: confirm that we had four concurrent executions (takes a few seconds to update)\n",
    "# Same results too:\n",
    "[result for result in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52465c0",
   "metadata": {},
   "source": [
    "Ideally, we should be able to scale out to as many available Lambda workers as possible (i.e. thousands of concurrent function invocations on different segments of a dataset -- a serverless domain decomposition) and not be limited by our local resources, though. \n",
    "\n",
    "This is a where AWS [Step Functions](https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html) can be very useful -- orchestrating large, embarrassingly parallel code execution across many Lambda workers with very little code (all we need to do is specify a graphical model for how our Lambda Function should be invoked!). Specifically, we'll be using the [\"map\" state](https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-creating-map-state-machine.html) to scatter input data to multiple Lambda workers at the same time and selecting the [express workflow Step Function option](https://docs.aws.amazon.com/step-functions/latest/dg/concepts-standard-vs-express.html) to a run our short job synchronously.\n",
    "\n",
    "(Demonstrate how to incorporate Lambda Function into Step Function workflow via graphical model in console)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74d449d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stateMachines': [{'stateMachineArn': 'arn:aws:states:us-east-1:459674479721:stateMachine:hello_world_sm', 'name': 'hello_world_sm', 'type': 'EXPRESS', 'creationDate': datetime.datetime(2022, 4, 17, 11, 49, 51, 254000, tzinfo=tzlocal())}, {'stateMachineArn': 'arn:aws:states:us-east-1:459674479721:stateMachine:word_count_sm', 'name': 'word_count_sm', 'type': 'EXPRESS', 'creationDate': datetime.datetime(2022, 4, 17, 17, 14, 23, 159000, tzinfo=tzlocal())}], 'ResponseMetadata': {'RequestId': '488f15bb-8862-4751-95b6-fd975b686636', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '488f15bb-8862-4751-95b6-fd975b686636', 'date': 'Mon, 18 Apr 2022 18:51:16 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '339'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "sfn = boto3.client('stepfunctions')\n",
    "response = sfn.list_state_machines()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30d11ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get arn for Step Function state machine\n",
    "state_machine_arn = [sm['stateMachineArn'] \n",
    "                     for sm in response['stateMachines'] \n",
    "                     if sm['name'] == 'hello_world_sm'][0]\n",
    "\n",
    "# generate test data to pass as input\n",
    "# \"Map\" will automatically invoke a separate Lambda function\n",
    "# to process each dictionary in the list (10 concurrently)\n",
    "data = [{\"key1\": 1, \"key2\": 2} for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0991d1d2",
   "metadata": {},
   "source": [
    "Once we have the identifier (ARN) for our Step Function state machine, we can pass in input data in JSON format. We have two options for execution -- synchronous execution (e.g. our notebook will wait for a response from AWS before moving on to the next cell), and asynchronous execution (which we might want to use if our Lambda functions were writing results to a cloud database and we don't need to wait for execution to finish before moving on with our code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e398718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"3\",\"3\",\"3\",\"3\",\"3\",\"3\",\"3\",\"3\",\"3\",\"3\"]\n"
     ]
    }
   ],
   "source": [
    "# Synchronous Execution\n",
    "response = sfn.start_sync_execution(\n",
    "    stateMachineArn=state_machine_arn,\n",
    "    name='sync_test',\n",
    "    input=json.dumps(data)\n",
    ")\n",
    "\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73297b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'executionArn': 'arn:aws:states:us-east-1:459674479721:express:hello_world_sm:async_test:85d421a1-dee9-49aa-b55a-f5ef305d59f9', 'startDate': datetime.datetime(2022, 4, 18, 13, 51, 16, 760000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '021e7925-cf81-4efb-a43f-ae168c6d48d9', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '021e7925-cf81-4efb-a43f-ae168c6d48d9', 'date': 'Mon, 18 Apr 2022 18:51:16 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '155'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Async; perhaps writing results to db and don't need to wait for execution to finish before moving on with code\n",
    "response = sfn.start_execution(\n",
    "    stateMachineArn=state_machine_arn,\n",
    "    name='async_test',\n",
    "    input=json.dumps(data)\n",
    ")\n",
    "\n",
    "print(response) # no results returned for async option\n",
    "# Can go into logs in Cloud Watch and see execution results (Express SF workflow)\n",
    "# Note that Standard Step Function workflow allows us to audit results via Boto3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa98d5",
   "metadata": {},
   "source": [
    "## Using AWS Lambda to make HTTP Requests in Parallel\n",
    "\n",
    "A common task for computational social scientists is making HTTP requests to access and process web data. It can be quite limiting to make these requests serially, though. When we do, the amount of data we are able to collect is limited both by our internet bandwidth and machine's ability to sequentially process the data.\n",
    "\n",
    "It would be much better to parallelize this workflow. Here, we'll take a look at how we could do this in a serverless fashion using the same workflow as above (Mapping Data to Lambda Functions via Step Functions). Specifically, we will call the [Google Books API](https://developers.google.com/books/docs/v1/getting_started) in parallel on a list of ISBNs (one API call can be constructed [like this](https://www.googleapis.com/books/v1/volumes?q=isbn:1906523371)), calculating the number of words used in the description for each book in our ISBN list (see workflow below). Word count is a simple metric (used here as a proof-of-concept), but it would also be possible to perform other Natural Language Processing routines using this same approach. Such a cloud workflow allows us to gather and process far greater amounts of data than would be otherwise possible on our local machines.\n",
    "\n",
    "![AWS Serverless Workflow](serverless_workflow.png)\n",
    "\n",
    "First, we'll need to load in a list of ISBNs (provided in this directory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63dbd7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('isbn.txt') as file:\n",
    "    isbn_list = [isbn.strip() for isbn in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0f62a",
   "metadata": {},
   "source": [
    "Then, we can write a function that will take in a list of ISBNs and compute the the number of words in the description of the corresponding book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a1feec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc_wc(isbn_list):\n",
    "    '''\n",
    "    Takes in a list of ISBNs and returns a list of description\n",
    "    word counts corresponding to each ISBN (via the Google\n",
    "    Books API).\n",
    "    '''\n",
    "    url = \"https://www.googleapis.com/books/v1/volumes?q=isbn:\"\n",
    "    wc_list = []\n",
    "    for isbn in isbn_list:\n",
    "        r = requests.get(url + isbn)\n",
    "        data = r.json()\n",
    "        # Try to get description, but if there is none, set\n",
    "        # word count to be 0 for that book\n",
    "        try:\n",
    "            description = data['items'][0]['volumeInfo']['description']\n",
    "            wc_list.append(len(description.split()))\n",
    "        except KeyError:\n",
    "            wc_list.append(0)\n",
    "    return wc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1588f3c",
   "metadata": {},
   "source": [
    "We can then call our function and it will sequentially request information and calculate the description word count for each one of our ISBNs in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf44ae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (in seconds) - Serial:  113.97650289535522\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "wc_list = get_desc_wc(isbn_list)\n",
    "time_elapsed = time.time() - start\n",
    "\n",
    "print(\"Time elapsed (in seconds) - Serial: \", time_elapsed)\n",
    "\n",
    "plt.hist(wc_list);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d891c1e6",
   "metadata": {},
   "source": [
    "This is a bit slow (exactly how slow will be variable and heavily based on your internet connection!), though, and could benefit from parallelization. One way we can do this in a \"serverless\" fashion is by using AWS Step Functions to invoke many AWS Lambda functions to make these ISBN API calls (and calculate the description word count) in parallel. \n",
    "\n",
    "In a personal AWS account, you can make up to [3000 concurrent Lambda invocations in an initial burst, scaling by an additional 500 instances each minute that your code runs (until your account's concurrency limit is reached)](https://docs.aws.amazon.com/lambda/latest/dg/invocation-scaling.html). Note, though, that we're limited in our AWS Academy accounts to making up to 10 concurrent Lambda invocations. As a result, we won't be able to see the same scalability as we would see in a personal account (it'll be up to ~300x slower!), but you can at least get the idea of how this pipeline can be constructed.\n",
    "\n",
    "To make this work, we'll do the same thing we did above in our \"Hello World\" case -- using Step Functions to invoke multiple Lambda functions in parallel and then return the output of the executions synchronously to our local machine. \n",
    "\n",
    "For our Lambda function, we can write a `lambda_handler` that uses our API request function above like so (to be run on mini-batches of the overall isbn list):\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "def get_desc_wc(isbn_list):\n",
    "    '''\n",
    "    Takes in a list of ISBNs and returns a list of description\n",
    "    word counts corresponding to each ISBN (via the Google\n",
    "    Books API).\n",
    "    '''\n",
    "    url = \"https://www.googleapis.com/books/v1/volumes?q=isbn:\"\n",
    "\n",
    "    wc_list = []\n",
    "    for isbn in isbn_list:\n",
    "        r = requests.get(url + isbn)\n",
    "        data = r.json()\n",
    "        # Try to get description, but if there is none, set\n",
    "        # word count to be 0 for that book\n",
    "        try:\n",
    "            description = data['items'][0]['volumeInfo']['description']\n",
    "            wc_list.append(len(description.split()))\n",
    "        except KeyError:\n",
    "            wc_list.append(0)\n",
    "    return wc_list\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    wc = get_desc_wc(event['isbn'])\n",
    "    return wc\n",
    "```\n",
    "\n",
    "The only tricky thing with running this particular code as a Lambda function is that we are importing in the `requests` module in order to make HTTP requests. Such dependencies are not included by default in Lambda's Python runtimes.\n",
    "\n",
    "In order to work with dependencies, we'll need to package our Lambda Function with all of its dependencies (which you can do manually [like so](https://docs.aws.amazon.com/lambda/latest/dg/python-package.html#python-package-create-package-with-dependency) or by adding a [predefined \"layer\" defined by a 3rd-party](https://api.klayers.cloud//api/v2/p3.9/layers/latest/us-east-1/html) via its ARN in the Lambda dashboard). \n",
    "\n",
    "Using the manual workflow linked above, we have included a zipped version of the Lambda function (with its dependencies) in this directory (`word_count.zip`) that you can upload and use (**walk through directory structure live in class**). You'll need to do the same if you want to provide added functionality to your Lambda functions (e.g. `BeautifulSoup` for web-scraping, `numpy` or `pandas` for analytical workflows, etc.). We'll also need to increase our lambda timeout so that we have enough time for our program to run to perform longer running jobs (the default is a 3s timeout).\n",
    "\n",
    "Let's use `boto3` this time to create our Lambda Function from our zipped `word_count.zip` (to demonstrate that we can do this programmatically as well as in the console as we did earlier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "290b271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access our class IAM role, which allows Lambda\n",
    "# to interact with other AWS resources\n",
    "iam_client = boto3.client('iam')\n",
    "role = iam_client.get_role(RoleName='LabRole')\n",
    "\n",
    "# Open our Zipped directory\n",
    "with open('word_count.zip', 'rb') as f:\n",
    "    lambda_zip = f.read()\n",
    "\n",
    "try:\n",
    "    # If function hasn't yet been created, create it\n",
    "    response = aws_lambda.create_function(\n",
    "        FunctionName='word_count',\n",
    "        Runtime='python3.9',\n",
    "        Role=role['Role']['Arn'],\n",
    "        Handler='word_count.lambda_handler',\n",
    "        Code=dict(ZipFile=lambda_zip),\n",
    "        Timeout=300\n",
    "    )\n",
    "except aws_lambda.exceptions.ResourceConflictException:\n",
    "    # If function already exists, update it based on zip\n",
    "    # file contents\n",
    "    response = aws_lambda.update_function_code(\n",
    "    FunctionName='word_count',\n",
    "    ZipFile=lambda_zip\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59521be0",
   "metadata": {},
   "source": [
    "Once we have our function, we can incorporate it into a Step Function state machine, like we did in our Hello World example (show in console).\n",
    "\n",
    "Once our Step Function is set, we're ready to provide data that will be spread across our Lambda worker invocations. Remember, we can only perform 10 concurrent invocations in AWS Academy, so we need to subdivide our list of ISBNs into 10 equal batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f883865",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500 // 10 # subdivide list of ISBNs into 10 equal batches\n",
    "isbn_batches = [{'isbn': isbn_list[i:i + n]} for i in range(0, len(isbn_list), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a326b834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 50\n"
     ]
    }
   ],
   "source": [
    "# 10 lists of 50 ISBNs\n",
    "print(len(isbn_batches), len(isbn_batches[0]['isbn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2c522a",
   "metadata": {},
   "source": [
    "Now, let's get our Step Function state machine arn and pass in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1b568fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get arn for Step Function state machine\n",
    "response = sfn.list_state_machines()\n",
    "state_machine_arn = [sm['stateMachineArn'] \n",
    "                     for sm in response['stateMachines'] \n",
    "                     if sm['name'] == 'word_count_sm'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "accd5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spread ISBN batches across Lambda workers\n",
    "start = time.time()\n",
    "response = sfn.start_sync_execution(\n",
    "    stateMachineArn=state_machine_arn,\n",
    "    name='isbn_500',\n",
    "    input=json.dumps(isbn_batches)\n",
    ")\n",
    "time_elapsed = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac88d799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.963962078094482\n"
     ]
    }
   ],
   "source": [
    "print(time_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbfd241",
   "metadata": {},
   "source": [
    "This is ~5x faster than the serial solution (meaning we can gather more data in the same amount of time, re: Gustafson's Law!). If we ran this same code on larger sets of ISBNs in a personal account, we would expect our compute time to remain similar, so long as we stay beneath the 3000 concurrent Lambda invocation maximum. You can also see that our parallel solution produces a similar distribution of word counts as the serial solution (with slight differences as a result of our permissive try/except logic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee1aa168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = json.loads(response['output'])\n",
    "plt.hist([num for sublist in output for num in sublist]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127f041a",
   "metadata": {},
   "source": [
    "So, we can quickly parallelize workflows in a serverless fashion using a combination of AWS Lambda and Step Functions. You can also create even more complicated workflows in Step Functions involving functional decomposition, multiple layers of Lambda function invocations, and more.\n",
    "\n",
    "One thing to note with the workflow above is that the payload size for inputs and outputs is not infinite (Step Functions will only accept inputs and outputs of size [262 KB or less](https://docs.aws.amazon.com/step-functions/latest/dg/avoid-exec-failures.html)). So, if you are working with really big inputs and/or outputs, you will want to input data from AWS cloud databases/distributed storage systems (e.g. providing the keys to the data you're referencing in the input JSON) and output data to a database/storage system within your Lambda function invocation as well. We'll talk more about how you can work with cloud databases (which allow you to make many concurrent reads and writes) next week to enable this increased scalability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
